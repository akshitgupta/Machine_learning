{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.10"
    },
    "colab": {
      "name": "NaiveBayes.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdBQR5k4Oe21"
      },
      "source": [
        "# Naive Bayes (the easy way)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE7f7U6GOe25"
      },
      "source": [
        "We'll cheat by using sklearn.naive_bayes to train a spam classifier! Most of the code is just loading our training data into a pandas DataFrame that we can play with:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hazbBAx_Oe26"
      },
      "source": [
        "import os\n",
        "import io\n",
        "import numpy\n",
        "from pandas import DataFrame\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "def readFiles(path):\n",
        "    for root, dirnames, filenames in os.walk(path):\n",
        "        for filename in filenames:\n",
        "            path = os.path.join(root, filename)\n",
        "\n",
        "            inBody = False\n",
        "            lines = []\n",
        "            f = io.open(path, 'r', encoding='latin1')\n",
        "            for line in f:\n",
        "                if inBody:\n",
        "                    lines.append(line)\n",
        "                elif line == '\\n':\n",
        "                    inBody = True\n",
        "            f.close()\n",
        "            message = '\\n'.join(lines)\n",
        "            yield path, message\n",
        "\n",
        "\n",
        "def dataFrameFromDirectory(path, classification):\n",
        "    rows = []\n",
        "    index = []\n",
        "    for filename, message in readFiles(path):\n",
        "        rows.append({'message': message, 'class': classification})\n",
        "        index.append(filename)\n",
        "\n",
        "    return DataFrame(rows, index=index)\n",
        "\n",
        "data = DataFrame({'message': [], 'class': []})\n",
        "\n",
        "data = data.append(dataFrameFromDirectory('e:/sundog-consult/Udemy/DataScience/emails/spam', 'spam'))\n",
        "data = data.append(dataFrameFromDirectory('e:/sundog-consult/Udemy/DataScience/emails/ham', 'ham'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkVU1QovOe3C"
      },
      "source": [
        "Let's have a look at that DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dAml2u7Oe3D"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQlfFRNwOe3I"
      },
      "source": [
        "Now we will use a CountVectorizer to split up each message into its list of words, and throw that into a MultinomialNB classifier. Call fit() and we've got a trained spam filter ready to go! It's just that easy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9ioaEbvOe3K"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "counts = vectorizer.fit_transform(data['message'].values)\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "targets = data['class'].values\n",
        "classifier.fit(counts, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcQnXXNnOe3P"
      },
      "source": [
        "Let's try it out:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGMGBocTOe3Q"
      },
      "source": [
        "examples = ['Free Coupoun now!!!', \"Hi Bob, how about a game of golf tomorrow?\"]\n",
        "example_counts = vectorizer.transform(examples)\n",
        "predictions = classifier.predict(example_counts)\n",
        "predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXxPq2I2Oe3X"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}